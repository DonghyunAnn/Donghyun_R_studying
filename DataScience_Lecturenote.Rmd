---
title: "Datascience lecturenote"
author: "D H An"
date: '2021 1 20 '
output: html_document
---
Base Library
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/user/Documents/github_Rstudio_workspace/Data")
setwd("C:/Users/user/Documents/github_Rstudio_workspace/Data")

library("dplyr")
library("tidyr")
library("stringr")
library('rpart') # Decision Tree
library('rpart.plot') # Decision Tree
library('class') #Knearest

```
## 데이터과학 2주차 강의노트
  
!(a>b) => 기존 TRUE FALSE값의 반대  
is.na(variable) => 결측값인주 물어보고 TRUE FALSE로 나옴  
typeof(variable) => 타입이 뭔지 알아보는거 / double=numeric  
  
### 벡터
```{r}
name_vector <- c('john', 'bob', 'sarah', 'alics')
name_vector[-1]
name_vector[c(2,4)]

some_vector <- c("John", "pocker player")
names(some_vector) <- c('name', 'job')
some_vector
some_vector[1]

weather_vector <- c("이름"="값", 'Mon'='sunny','Tues'='Rainy','Wed'='Cloudy','Thur'='Foggy',"Sat"='sunny',"Sun"="Cloudy")
names(weather_vector)
weather_vector[2]

a_vector <- 1:10 # seq(1,10)
b_vector <- seq(1,10,2)
c_vector <- rep(1:3,3)
d_vector <- rep(1:3,each=3)
c(a_vector,b_vector) # c(name_vector,a_vector)

a_vector <- c(1,5,2,7,8,2,3)
b_vector <- seq(1,10,3)
intersect(a_vector,b_vector) #교집합 union합집합 setdiff차집합 unique(중복제거) sum mean

#유용한 기능 
a_vector+10
a_vector>4
sum(a_vector>4)

#selection
sample_vector <- c(1,4,NA,2,1,NA,4,NA)
sample_vector[c(T,T,F,T,F,T,F,T)]
sample_vector
is.na(sample_vector)
sum(is.na(sample_vector))#na 몇개인지
na.omit(vector)# 결측값 제거
```


### matrix 행렬
```{r}
matrix(1:9, byrow=TRUE, nrow=3) # 열 방향으로 전개

new_hope <- c(460,314)
empire_strikes <- c(290,247)
return_jedi <- c(309,165)
star_wars_matrix <- matrix(c(new_hope,empire_strikes,return_jedi),nrow = 3,byrow=TRUE)
star_wars_matrix

region <- c('us','non us')
titles <- c('a new hope', 'the empire strikes back', 'return of the jedi')
colnames(star_wars_matrix) <- region
rownames(star_wars_matrix) <- titles
star_wars_matrix

rowSums(star_wars_matrix)#행 합
colSums(star_wars_matrix)#열 합

worldwide_vector <- rowSums(star_wars_matrix)
all_wars_matrix <- cbind(star_wars_matrix,worldwide_vector) #열끼리 묶음 열이추가
all_wars_matrix
apply(all_wars_matrix,2,mean)
box_office <- c(474,552,310,338,380,468)
star_wars_matrix2 <- matrix(box_office,nrow = 3, byrow = TRUE, 
                            dimnames = list(c('the phantom menace','attack of the clones', 'revenge ofthe sith'),c('us', 'nonus')))
star_wars_matrix2
rbind(star_wars_matrix,star_wars_matrix2) # 행끼리 묶음 행이 추가
#행렬 곱샘 %*% 각 성분끼리 곱은 *
```
factor변수
```{r}
sex_vector <- c("male","female","female","male","male") #type=character
factor_sex_vector <- factor(sex_vector) #type=factor 
#str() 변수의 구조를 보는 것임
typeof(factor_sex_vector)#integer인 이유는 수준이 1,2와 같이 나타나기 때문
str(factor_sex_vector)
levels(factor_sex_vector)
#Changing levels  
survey_vector <- c("m","f","f","m","m")
factor_survey_vector <- factor(survey_vector)
levels(factor_survey_vector) <- c('female','male')
```

### Dataframe & List
```{r}
#Dataframe
str(mtcars)
dim(mtcars)
head(mtcars)
mtcars$mpg >20
mtcars[mtcars$mpg>20,]#df[조건,(변수이름)]으로 select할 수 있음

#List
my_list <- list('a'=a_vector,'starwars'=star_wars_matrix,'cars'=mtcars)
names(my_list) <- c('a','starwars','car')
#정보 부르는법 my_list[[1]] 1자리에 name,혹은 my_list$starwars
```
------------------------------------------------------------------------------
## 데이터과학 3주차 강의노트  
  
### if문
if (condition) {exp}  
if (condition) {exp} else{exp}   
  
### for문
for(var in seq){exp}  
  
### ifelse문
ifelse(조건, 'true일때결과','False일때결과')


### DataLoading
getwd()
setwd("경로")
### Save & load
csv로 저장 -> write.csv(저장 대상, "저장할 파일 이름.csv", row.names = F or T,)
tsv로 저장 -> write.csv(저장 대상, "저장할 파일 이름.tsv", row.names = F or T, sep='\t')
  
Rdata로 저장 & 불러오기
save(벡터,벡터,다른거, file='파일이름.Rdata')
load('파일이름')

```{r}
#read.csv
getwd()
setwd("C:/Users/user/Documents/github_Rstudio_workspace/Data")
pools <- read.csv('swimming_pools.csv',stringsAsFactors = FALSE)
str(pools)
#read.table
hotdogs <- read.table('hotdog.txt',sep='\t',col.names = c('type','calories','sodium'))
hotdogs$cal.type <- ifelse(hotdogs$calories>150, 'heavy','light')#추가하고싶은변수그냥 냅다 설정하고 때려박으면됨
#Save
write.csv(hotdogs,file='newhotdogs.csv',row.names = F)
write.table(hotdogs,file='newhotdogs.tsv',row.names = F, sep='\t')
```

### 유용한 함수 사용
사용자 정의 함수 함수명 <- function(변수){return(출력값)}  
runif(개수) ->0~1 에 대해 난수생성하는것(set.seed(2018)등 숫자설정하면 난수가 똑같이나옴)  
apply(x,margin,function) margin -> 1=row, 2=column 즉 dataframe을 슬라이스내서 그걸로 함수적용하는것
* lapply(x,function) -> listapply라고 보면됨
* sapply(x,function) -> 결과가 벡터나 행렬로 나옴  #sapply(x,function(x){return값}) -> 익명 함수
* tapply는 행렬 기준임 tapply(다룰 백터, 그룹백터 혹은 그룹으로 나눌만한 조건, function)
* aggregate(종속변수~독립변수, data=어떤데이터, function)
* sort(백터, decreasing=T)
* order(백터) 결과는 정렬되는 인덱스 백터가 나옴 **sort는 order을 내포하고 있음**
* 즉 order는 기준을 설정하고 데이터 프레임 내 정렬할 때 쓰기 좋음
* sample(x,샘플개수,replace=False) 
* split(df, split_var) ->데이터 프레임을 어떤 기준으로 쪼개서 리스트로 나타내주는 것
* subset(dataframe, 조건)
* merge(df1,df2)
* which(조건) ->조건을 충족한 인덱스를 찾는것 위치를 찾는것
* cut(vector, breaks = c(0,2,4,6), label=c(1,2,3),right) -> 명목형 변수로 나타낼 때
* quantile->기본이 4분위수 하지만 probs로 내가 원하는 퍼센테이지 볼 수 있음
* paste 1. 문자끼리 붙이기 2. 벡터 인덱스 같은것끼리 붙이기
```{r}
#apply
tapply(iris$Sepal.Length, iris$Species, mean)
tapply(mtcars$wt,mtcars$mpg>20, mean)
#sort,order
sort(mtcars$mpg)
order(mtcars$mpg)
mtcars[order(mtcars$mpg, decreasing=T),]
iris[order(iris$Petal.Length, decreasing=T),]
sample(1:150, 10,replace = FALSE)
iris[sample(1:150, 10,replace = FALSE),]
sample(a_vector,length(a_vector))#순서섞는것도 가능
#split
split(mtcars,mtcars$cyl)
split(iris,iris$Petal.Width>2)
#merge
x <- data.frame(name=c("john",'bob','carol'),
                math=c(70,80,90))
y <- data.frame(name=c('john','bob','alice'),
                history=c(100,80,90))
merge(x,y)
merge(x,y,all=T)
#cut
mtcars$wt
cut(mtcars$wt,breaks = c(0,2,4,6), label=c(1,2,3), right=TRUE)
#quantile
quantile(iris$Sepal.Length, probs = c(0.1,0.9))
cutpoint <- quantile(mtcars$mpg,probs=c(0,0.25,0.75,1))
mtcars$fuelefficiency <- cut(mtcars$mpg,breaks=cutpoint,include.lowest = T)
#paste
x <- seq(2,20.2)
y <- LETTERS[1:10]
paste(x,y,sep = ';')
paste(paste(x,y), collapse = ',')
outcome <- 'mpg'
input_var <- names(mtcars)[2:6]
paste(outcome,paste(input_var,collapse='+'),sep = '~')
```
## 데이터과학4주차 강의노트
### Explore Data
```{r}
bmi<- read.csv("C:/Users/user/Documents/github_Rstudio_workspace/Data/bmi_clean.csv",header = TRUE)
str(bmi)
dim(bmi)
names(bmi)
class(bmi)
summary(bmi)
glimpse(bmi)
#시각화
hist(bmi$Y1980)
plot(x=bmi$Y1980,y=bmi$Y2008)
```


### Data Clearing
* gather(df, columnname,columnval,columnname 범위) # 넓은 데이터를 좁게
* spread(data, 쪼갤column) #근데 이걸 구분시켜줄 어떤 변수가 있어야함
* separate(df, col, c(변수,변수, ...),sep='-'는 디폴트) 변수를 나눠주는 것 
* unite(df,변수이름, col, col)

```{r}
wide_df <- data.frame(col = c('X', 'Y'), A = c(1,4), B = c(2,5), C = c(3,6))
long_df <- gather(wide_df,my_key, my_val, 2:4)
spread(long_df,my_key,my_val)
#exercise01
bmi_long <- gather(bmi, year, bmi_val, 2:30)
bmi_long
bmi_wide <- spread(bmi_long, year,bmi_val)
bmi_wide
#exercise02
bmic <- read.csv('C:/Users/user/Documents/github_Rstudio_workspace/Data/bmi_cc.csv', header=TRUE)
head(bmic)
bmic_clean <- separate(bmic,Country_ISO,c('Country','ISO'),sep='/')
unite(bmic_clean,Country_ISO,Country,ISO, sep='/')
```

### Type Conversion 
* class()
* as.logical()
* as.numeric()
* library('lubridate') => ymd, mdy <-  date, hms <- time
```{r}
date <- c('2010-10-01','2010-12-31')
summary(as.Date(date))
```
### String Manipulation
* str_trim() :좌우 공백제거
* str_pad(변수, with=숫자, side='left', pad='0') :자리수맞춰주기
* str_detect(vector,'찾고싶은거')
* str_replace(vector,'빼고싶은거','넣고싶은거')
* tolower() : 소문자
* toupper() : 대문자
```{r}
#exercise3
students2 <- read.csv('C:/Users/user/Documents/github_Rstudio_workspace/Data/students2.csv',header=TRUE,stringsAsFactors = F)
str(students2)
library('lubridate')
students2$dob <- ymd(students2$dob)
students2$nurse_visit <- ymd_hms(students2$nurse_visit)
str(students2)

#exercise4
str_detect(students2$dob,'1997')
students2$sex <- str_replace(students2$sex,'F','Female')
students2$sex <- str_replace(students2$sex,'M','Male')
head(students2)
```

### NA Handling
* is.na(df) : TRUE FALSE로 결과치 나옴
* any(is.na(df)) : 결측치가 있냐
* sum(is.na(df)) : 개수새기
* complete.cases(df) : 결측치가 하나도 없는 행=TRUE
* df[complete.cases(df),] : na가 없는 행
* na.omit(df) : na행 다 날려버리기기  

```{r}
students3 <- read.csv('C:/Users/user/Documents/github_Rstudio_workspace/Data/students3.csv',header=TRUE,stringsAsFactors = F)
str(students3)
attach(students3)
summary(age)
summary(absences)
hist(age)
hist(absences)
students3$absences <- str_replace(absences,'-1','NA')
students3
str_detect(absences,'NA')
```
## 데이터과학 5주차 강의노트
### Decision Tree
* 대출클럽같은 곳에 많이 쓰임
* Entropy = 혼잡도 : 데이터가 비슷하게 섞여있으면 높고, 한가지 종류만 있으면 낮음
* {sigma_(k- > 분할개수) -p_k*logp_k} {p_k=전체중에 해당 부분}
  
* root= 전체, split=나눈거 , n=샘플수, loss=rapid가 아닌 수(deafult, rapid)
* 해석방법: root 전체개수 나눈개수 구하고자하는것(x) (1-p(x),p(x))
* prepruning은 미리 복잡함의 정도를 정해두는 것임 [maxdepth ,minimumsplit (쪼개진 샘플 수가 일정 수준 이하로 내려가지 않게 하는 것)]
* postpruning은 다 만들고 어느 선에서 정리하는 것 [plotcp(model)쓰면 model의 에러값과 cp의 값 plotd이 뜨는데 여기서 cp값 보고 결정]
* predict(model,data,type='class' 등등)
* cp=0을 둔다는 것은 제한없이 쭉 끝까지 한다는 뜻
```{r}

load(url('https://github.com/hbchoi/SampleData/blob/master/dtree_data.RData?raw=true'))
str(loans)
loan_model <- rpart(outcome~loan_amount+credit_score,data=loans,method='class',
                    control=rpart.control(cp=0))
loan_model
rpart.plot(loan_model)
rpart.plot(loan_model, type=3, box.palette=c('red','green'),fallen.leaves= TRUE)


#Prepruning maxdepth로 정하기
loan_model <- rpart(outcome ~ ., data=loans, method='class',
                    control=rpart.control(cp=0,maxdepth=6))
#Prepruning minimumsplit으로 정하기
loan_model <- rpart(outcome ~ ., data=loans, method='class',
                    control=rpart.control(cp=0,minsplit = 500))
#Postpruning
loan_model_pruned <- prune(loan_model,cp=0.0014) # 이런 식으로 결정
```
###K Nearest Neighbors
* pred <- knn(train, test, cl, k = 1, l = 0, prob = FALSE, use.all = TRUE)
- train : 훈련 데이터셋 (matrix or data frame)
- test : 테스트 데이터셋 (matrix or data frame)
- cl: 훈련 데이터셋의 그룹(class) 정보 (factor)
- k : 이웃(neighbour)의 수
- l : 명확한 결정을 위한 최소 유효 수, 그렇지 않은 경우 의심
- prob: 만약 이것이 트루라면, 프로브 속성에서 당첨된 비율을 반환한다.
- use.all: 만약 트루라면, K번째의 최대치에 해당하는 모든 거리가 포함된다. 거짓이면 k의 이웃 포인트를 정확히 사용하기 위해 K번째와 같은 거리를 무작위로 선택한다.
* 유클리디안 거리를 구하기 위해 표준화를 시켜야 함

```{r}
wbcd <- read.csv("https://github.com/hbchoi/SampleData/raw/master/wisc_bc_data.csv",stringsAsFactors=F)
wbcd <- wbcd[,-1]
wbcd$diagnosis <- ifelse(wbcd$diagnosis=='B',' Benign','Malignant')
table(wbcd$diagnosis)

#min-max normalization for Euclidean Distance
minmax_norm <- function(x){
  (x-min(x))/(max(x)-min(x))
}
wbcd_norm <- sapply(wbcd[-1], minmax_norm)
summary(wbcd)
summary(wbcd_norm)
#train test
wbcd_train <- wbcd_norm[1:469,]
wbcd_test <- wbcd_norm[470:569,]
wbcd_train_label <- wbcd[1:469,1]
wbcd_test_label <- wbcd[470:569,1]

# k개수는 총 행 개수의 루트로 구했음
sqrt(nrow(wbcd_train))
wbcd_test_pred <- knn(train=wbcd_train,test=wbcd_test,cl=wbcd_train_label,k=21)
#accuracy
mean(wbcd_test_label==wbcd_test_pred)
#confusion matrix
cmat <- table(wbcd_test_label,wbcd_test_pred)
cmat
precision <- cmat[2,2]/sum(cmat[,2])
recall <- cmat[2,2]/sum(cmat[2,])
#암인사람 주변이 암인사람 비율, 암이 아닌사람 주위 암이 아닌사람 비율
wbcd_test_pred <- knn(train=wbcd_train,test=wbcd_test,cl=wbcd_train_label,k=21,prob=TRUE)
head(attributes(wbcd_test_pred)$prob)
head(wbcd_test_pred)
wbcd_test_pred_prob <-  ifelse(wbcd_test_pred == 'M', attributes(wbcd_test_pred)$prob, 1-attributes(wbcd_test_pred)$prob)
head(wbcd_test_pred_prob)

###시각화 AUC
library(ROCR)
plot(performance(prediction(wbcd_test_pred_prob,wbcd_test_label=='M'),'tpr','fpr'))
calAUC <- function(predCol,targetCol){
  perf <- performance(prediction(predCol,targetCol),'auc')
  as.numeric(perf@y.values)
}

calAUC(wbcd_test_pred_prob,wbcd_test_label=='M')
performance(prediction(wbcd_test_pred_prob,wbcd_test_label=='M'),'auc')


#adjusting threshold
threshold <- 0.1
wbcd_test_pred_new <- ifelse(wbcd_test_pred_prob > threshold, 'M','B')
cmat <- table(wbcd_test_label, wbcd_test_pred_new)

#accuracy
mean(wbcd_test_label == wbcd_test_pred_new)
precision <- cmat[2,2]/sum(cmat[,2])
recall <- cmat[2,2]/sum(cmat[2,])
```



#######더미변수########
#dummy coding
#one hot encoding
library(caret)
#predict(dummyVars(~cbwd,data=data1),data1)
