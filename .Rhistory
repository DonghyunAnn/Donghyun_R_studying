wbcd_test <- wbcd_norm[470:569,]
wbcd_train_label <- wbcd[1:469,1]
wbcd_test_label <- wbcd[470:569,1]
#accuracy
mean(wbcd_test_label==wbcd_test_pred)
wbcd <- read.csv("https://github.com/hbchoi/SampleData/raw/master/wisc_bc_data.csv",stringsAsFactors=F)
wbcd <- read.csv("https://github.com/hbchoi/SampleData/raw/master/wisc_bc_data.csv",stringsAsFactors=F)
wbcd <- wbcd[,-1]
wbcd$diagnosis <- ifelse(wbcd$diagnosis=='B',' Benign','Malignant')
table(wbcd$diagnosis)
#min-max normalization for Euclidean Distance
minmax_norm <- function(x){
(x-min(x))/(max(x)-min(x))
}
wbcd_norm <- sapply(wbcd[-1], minmax_norm)
wbcd_norm <- sapply(wbcd[-1], minmax_norm)
summary(wbcd)
summary(wbcd_norm)
summary(wbcd_norm)
#train test
wbcd_train <- wbcd_norm[1:469,]
summary(wbcd_norm)
#train test
wbcd_train <- wbcd_norm[1:469,]
wbcd_test <- wbcd_norm[470:569,]
summary(wbcd)
summary(wbcd_norm)
#train test
wbcd_train <- wbcd_norm[1:469,]
wbcd_test <- wbcd_norm[470:569,]
wbcd_train_label <- wbcd[1:469,1]
wbcd_test_label <- wbcd[470:569,1]
wbcd_test_label <- wbcd[470:569,1]
# k개수는 총 행 개수의 루트로 구했음
sqrt(nrow(wbcd_train))
# k개수는 총 행 개수의 루트로 구했음
sqrt(nrow(wbcd_train))
wbcd_test_pred <- knn(train=wbcd_train,test=wbcd_test,cl=wbcd_train_label,k=21)
#accuracy
mean(wbcd_test_label==wbcd_test_pred)
wbcd_test_label
wbcd_test_pred
wbcd_test_label==wbcd_test_pred
mean
#accuracy
mean(wbcd_test_label==wbcd_test_pred)
#confusion matrix
cmat <- table(wbcd_test_label,wbcd_test_pred)
cmat
# k개수는 총 행 개수의 루트로 구했음
sqrt(nrow(wbcd_train))
wbcd_test_pred <- knn(train=wbcd_train,test=wbcd_test,cl=wbcd_train_label,k=21)
library('class') #Knearest
wbcd_test_pred <- knn(train=wbcd_train,test=wbcd_test,cl=wbcd_train_label,k=21)
#accuracy
mean(wbcd_test_label==wbcd_test_pred)
#confusion matrix
cmat <- table(wbcd_test_label,wbcd_test_pred)
cmat
precision <- cmat[2,2]/sum(cmat[,2])
recall <- cmat[2,2]/sum(cmat[2,])
#암인사람 주변이 암인사람 비율, 암이 아닌사람 주위 암이 아닌사람 비율
wbcd_test_pred <- knn(train=wbcd_train,test=wbcd_test,cl=wbcd_train_label,k=21,prob=TRUE)
attributes(wbcd_test_pred)
attributes(wbcd_test_pred)$prob
head(wbcd_test_pred)
wbcd_test_pred_prob <-  ifelse(wbcd_test_pred == 'M', attributes(wbcd_test_pred)$prob, 1-attributes(wbcd_test_pred)$prob)
head(wbcd_test_pred_prob)
wbcd_test_pred_prob
wbcd_test_pred
wbcd_train_label
wbcd_test
wbcd_train_label
attributes(wbcd_test_pred)$prob
1-attributes(wbcd_test_pred)$prob
wbcd_test_pred_prob <-  ifelse(wbcd_test_pred == 'M', attributes(wbcd_test_pred)$prob, 1-attributes(wbcd_test_pred)$prob)
head(wbcd_test_pred_prob)
library(ROCR)
plot(performance(prediction(wbcd_test_pred_prob,wbcd_test_label=='M'),'tpr','fpr'))
library('ROCR')
library('ROCR')
plot(performance(prediction(wbcd_test_pred_prob,wbcd_test_label=='M'),'tpr','fpr'))
#암인사람 주변이 암인사람 비율, 암이 아닌사람 주위 암이 아닌사람 비율
wbcd_test_pred <- knn(train=wbcd_train,test=wbcd_test,cl=wbcd_train_label,k=21,prob=TRUE)
head(attributes(wbcd_test_pred)$prob)
head(wbcd_test_pred)
wbcd_test_pred_prob <-  ifelse(wbcd_test_pred == 'M', attributes(wbcd_test_pred)$prob, 1-attributes(wbcd_test_pred)$prob)
head(wbcd_test_pred_prob)
# k개수는 총 행 개수의 루트로 구했음
sqrt(nrow(wbcd_train))
wbcd_test_pred <- knn(train=wbcd_train,test=wbcd_test,cl=wbcd_train_label,k=21)
#accuracy
mean(wbcd_test_label==wbcd_test_pred)
#confusion matrix
cmat <- table(wbcd_test_label,wbcd_test_pred)
cmat
precision <- cmat[2,2]/sum(cmat[,2])
recall <- cmat[2,2]/sum(cmat[2,])
#암인사람 주변이 암인사람 비율, 암이 아닌사람 주위 암이 아닌사람 비율
wbcd_test_pred <- knn(train=wbcd_train,test=wbcd_test,cl=wbcd_train_label,k=21,prob=TRUE)
head(attributes(wbcd_test_pred)$prob)
head(wbcd_test_pred)
wbcd_test_pred_prob <-  ifelse(wbcd_test_pred == 'M', attributes(wbcd_test_pred)$prob, 1-attributes(wbcd_test_pred)$prob)
head(wbcd_test_pred_prob)
plot(performance(prediction(wbcd_test_pred_prob,wbcd_test_label=='M'),'tpr','fpr'))
(wbcd_test_pred_prob
wbcd_test_pred_prob
wbcd_test_pred_prob
wbcd_test_label=='M'
prediction(wbcd_test_pred_prob,wbcd_test_label=='M')
plot(performance(prediction(wbcd_test_pred_prob,int(wbcd_test_label=='M')),'tpr','fpr'))
plot(performance(prediction(wbcd_test_pred_prob,as.numeric(wbcd_test_label=='M')),'tpr','fpr'))
plot(performance(prediction(wbcd_test_pred,wbcd_test_label=='M'),'tpr','fpr'))
plot(performance(prediction(wbcd_test_pred_prob,wbcd_test_label=='Malignant'),'tpr','fpr'))
calAUC <- function(predCol,targetCol){
perf <- performance(prediction(predCol,targetCol),'auc')
as.numeric(perf@y.values)
}
calAUC(wbcd_test_pred_prob,wbcd_test_label=='M')
calAUC(wbcd_test_pred_prob,wbcd_test_label=='Malignant')
performance(prediction(wbcd_test_pred_prob,wbcd_test_label=='M'),'auc')
'M'
performance(prediction(wbcd_test_pred_prob,wbcd_test_label=='Malignant'),'auc')
#adjusting threshold
threshold <- 0.1
wbcd_test_pred_new <- ifelse(wbcd_test_pred_prob > threshold, 'M','B')
cmat <- table(wbcd_test_label, wbcd_test_pred_new)
#accuracy
mean(wbcd_test_label == wbcd_test_pred_new)
precision <- cmat[2,2]/sum(cmat[,2])
recall <- cmat[2,2]/sum(cmat[2,])
precision
recall
#accuracy
mean(wbcd_test_label == wbcd_test_pred_new)
wbcd_test_pred_prob
wbcd_test_pred_new <- ifelse(wbcd_test_pred_prob > threshold, 'Malignant','Benign')
cmat <- table(wbcd_test_label, wbcd_test_pred_new)
#accuracy
mean(wbcd_test_label == wbcd_test_pred_new)
precision <- cmat[2,2]/sum(cmat[,2])
recall <- cmat[2,2]/sum(cmat[2,])
precision
recall
#accuracy
mean(wbcd_test_label == wbcd_test_pred_new)
load(url('https://github.com/hbchoi/SampleData/raw/master/insurance.RData'))
str(insurance)
summary(insurance)
model <- lm(outcome~independent,data=train)
attach(insurance)
model <- lm(outcome~independent,data=train)
rgroup <- runif(nrow(insurance))
rgroup <- runif(nrow(insurance))
rgroup
train <- subset(insurance, rgroup<=0.8)
test <- subset(insurance,rgroup>0.8)
#model & predict
ins_model <- lm(charges~age + sex + bmi+children + smoker + region,train)
train$pred <- predict(ins_model,train)
test$pred <- predict(ins_model,test)
#function
calcrmse <- function(real,estimation){
return(sqrt(mean((real-estimation)**2)))
}
calr2 <- function(real,estimation){
rss <- sum((real-estimation)**2)
sst <- sum((real-mean(real))**2)
return(1-rss/sst)
}
calcrmse(train$charges,train$pred)
calr2(train$charges,train$pred)
calcrmse(test$charges,test$pred)
calr2(test$charges,test$pred)
summary(ins_model)
ggplot(train,aes(x=pred, y=charges))+
geom_point(alpha=0.2, col='black')+
geom_smooth()+
geom_line(aes(x=charges,y=charges),col='blue',linetype=2)
library('ggplot2') #시각화
ggplot(train,aes(x=pred, y=charges))+
geom_point(alpha=0.2, col='black')+
geom_smooth()+
geom_line(aes(x=charges,y=charges),col='blue',linetype=2)
ggplot(train,aes(x=pred,y=pred-charges))+
geom_point(alpha=0.2,col='black')+
geom_smooth()+
geom_hline(yintercept=0,col='blue',linetype=2)
#모형개선
train$bmi30 <- ifelse(train$bmi>=30,1,0)
test$bmi30 <- ifelse(test$bmi>=30,1,0)
ins_model <- lm(charges~age+I(age^2)+sex+bmi+children+bmi30*smoker+region, train)
train$pred <- predict(ins_model,train)
test$pred <- predict(ins_model,test)
calcrmse(train$charges,train$pred)
calr2(train$charges,train$pred)
calcrmse(test$charges,test$pred)
calr2(test$charges,test$pred)
summary(ins_model)
load(url('https://github.com/hbchoi/SampleData/raw/master/NatalRiskData.rData'))
str(sdata)
#train test set
train <- sdata[sdata$ORIGRANDGROUP<=5,]
test <- sdata[sdata$ORIGRANDGROUP>5,]
complications <- c('ULD_MECO','ULD_PRECIP','ULD_BREECH')
riskfactors <- c('URF_DIAB','URF_CHYPER','URF_PHYPER','URF_ECLAM')
y <- 'atRisk'
complications <- c('ULD_MECO','ULD_PRECIP','ULD_BREECH')
riskfactors <- c('URF_DIAB','URF_CHYPER','URF_PHYPER','URF_ECLAM')
y <- 'atRisk'
x <- c('PWGT','UPREVIS','CIG_REC','GESTREC3','DPLURAL',complications,riskfactors)
fmla <- paste(y,paste(x,collapse='+'),sep='~')
fmla
#logistic model
model <- glm(fmla,data=train,family=binomial(link='logit'))
train$pred <- predict(model,newdata=train,type='response') #newdata=예측하고자하는 데이터
test$pred <-predict(model,newdata=test,type='response') #type='response'로 해주어야 확률값이 나옴
#예측된 값 보기
test[20:40,c('pred','atRisk')]
aggregate(pred~atRisk,data=train,mean)
aggregate(pred~atRisk,data=test,mean)
ggplot(train, aes(x=pred,color=atRisk,linetype=atRisk))+geom_density()
test$pred
str(sdata)
aggregate(pred~atRisk,data=train,mean)
aggregate(pred~atRisk,data=test,mean)
ggplot(train, aes(x=pred,color=atRisk,linetype=atRisk))+geom_density()
e
#Data load
load(url('https://github.com/hbchoi/SampleData/raw/master/adult.RData'))
set.seed(2020)
#train, test set 설정
n_sample <- nrow(adult)
rgroup <- runif(n_sample)#균등분포에서의 난수생성
adult.train <- subset(adult,rgroup<=0.8)
adult.test <- subset(adult, rgroup>0.8)
#table 쓰는 법
table(adult.train$income_mt_50k)#명목형 변수 빈도를 보여줌
prop.table(table(adult.train$income_xymt_50k))#소수점 비율로 보여줌
prop.table(table(adult.train$income_xymt_50k))#소수점 비율로 보여줌
adult.train$income_xymt_50k
prop.table(table(adult.train$income_mt_50k))#소수점 비율로 보여줌
# 모델 전 처리
tble <- table(adult.train$occupation,adult.train$income_mt_50k)#row,column
tble
sv_model_job <- prop.table(tble,margin = 1)[,2] # 뒤에 [,] 붙여서 원하는 행 열 뽑아낼 수 있음
sv_model_job
tble
prop.table(tble,margin = 1)
tble
sv_model_job <- prop.table(tble,margin = 1)[,2] # 뒤에 [,] 붙여서 원하는 행 열 뽑아낼 수 있음
sv_model_job
adult.train$occupation
sv_model_job[adult.train$occupation]
sv_model_job
adult.train$est_prob <- sv_model_job[adult.train$occupation]
#간단한 모델 만들기
threshold <- 0.4
adult.train$prediction <- adult.train$est_prob>threshold
head(adult.train[,c('occupation','est_prob','prediction','income_mt_50k')],10)
#얼마나 맞췄는지 확인
conf.table <- table(pred=adult.train$prediction, actual=adult.train$income_mt_50k)
conf.table
accuracy <- sum(diag(conf.table))/sum(conf.table)
accuracy
accuracy
# 모델 전 처리
tble <- table(adult.train$education,adult.train$income_mt_50k)
sv_model_job <- prop.table(tble,margin = 1)[,2]
adult.train$est_prob <- sv_model_job[adult.train$education]
#역치0.5
threshold <- 0.5
adult.train$prediction <- adult.train$est_prob>threshold
conf.table <- table(pred <- adult.train$prediction,actual <- adult.train$income_mt_50k)
precision <- sum(conf.table[2,2])/sum(conf.table[2,])
accuracy <- sum(diag(conf.table))/sum(conf.table)
accuracy <- sum(diag(conf.table))/sum(conf.table)
accuracy
recall <-  sum(conf.table[2,2])/sum(conf.table[,2])
recall
precision <- sum(conf.table[2,2])/sum(conf.table[2,])
precision
#역치0.6
threshold <- 0.6
adult.train$prediction <- adult.train$est_prob>threshold
conf.table <- table(pred <- adult.train$prediction,actual <- adult.train$income_mt_50k)
accuracy
recall
precision
#test set 기준으로 얼마나 맞았는지 확인
tble <- table(adult.test$education,adult.test$income_mt_50k)
sv_model_job <- prop.table(tble,margin = 1)[,2]
adult.test$est_prob <- sv_model_job[adult.test$education]
threshold <- 0.5
adult.test$prediction <- adult.test$est_prob>threshold
conf.table <- table(actual <- adult.test$prediction, actual <- adult.test$income_mt_50k)
accuracy <- sum(diag(conf.table))/sum(conf.table)
library('ROCR')
library('ROCR') #AUC 그래프
plot(performance(prediction(adult.test$est_prob,adult.test$income_mt_50k),'tpr','fpr')) #앞변수로 뒷변수를 얼마나 잘 예측하 수 있느냐
#연속형을 명목형으로 바꿔서 분석
adult.train$age_group <- cut(adult.train$age, breaks=c(0,20,30,40,50,60, Inf),labels=c('under20','20s','30s','40s','50s','over60'),
right = F)
tble <- table(adult.train$age_group,adult.train$income_mt_50k)
sv_model_age <- prop.table(tble,margin=1)[,2]
adult.train$est_prob <- sv_model_age[adult.train$age_group]
threshold <- 0.3
adult.train$predictoni <- adult.train$est_prob >threshold
#accuracy 사용자 정의 함수
get_accuracy <- function(pred,actual){
tble <- table(pred,actual)
return(round(sum(diag(tble))/sum(tble),3))
}
get_accuracy(adult.train$prediction,adult.train$income_mt_50k)
#AUC curve Visualization
plot(performance(prediction(adult.test$est_prob,adult.test$income_mt_50k),'tpr','fpr')) #앞변수로 뒷변수를 얼마나 잘 예측하 수 있느냐
#Data load
load(url('https://github.com/hbchoi/SampleData/raw/master/insurance.RData'))
#Data Browse
hist(insurance$charges)
plot(density(log(insurance$charges)))#log를 씌우면 편포가 정규모양으로 바뀔 수 있음
insurance$logcharges <- log10(insurance$charges)
#Data Browse
hist(insurance$charges)
plot(density(log(insurance$charges)))#log를 씌우면 편포가 정규모양으로 바뀔 수 있음
plot(density(log(insurance$charges)))#log를 씌우면 편포가 정규모양으로 바뀔 수 있음
insurance$logcharges <- log10(insurance$charges)
#test, training set
set.seed(2020)
n_sample <- nrow(insurance)
rgroup <- runif(n_sample)
train <- subset(insurance,rgroup<=0.8)
test <- subset(insurance,rgroup>0.8)
#model 전처리
sv_reg_smoker <- tapply(train$logcharges, train$smoker,mean)
load(url('https://github.com/hbchoi/SampleData/blob/master/dtree_data.RData?raw=true'))
#test, training set
set.seed(2020)
n_sample <- nrow(insurance)
rgroup <- runif(n_sample)
train <- subset(insurance,rgroup<=0.8)
test <- subset(insurance,rgroup>0.8)
#model 전처리
sv_reg_smoker <- tapply(train$logcharges, train$smoker,mean)
#model 전처리
sv_reg_smoker <- tapply(train$logcharges, train$smoker,mean)
sv_reg_smoker
train$logcharges,
train$logcharges
train$smoker
tapply(train$logcharges, train$smoker,mean)
#model 전처리
sv_reg_smoker <- tapply(train$logcharges, train$smoker,mean)
sv_reg_smoker[train$smoker]
train$pred <- sv_reg_smoker[train$smoker]
train$pred
train$pred
train
train$pred <- sv_reg_smoker[train$smoker]
train$error <- train$logcharges-train$pred
sv_reg_smoker
train$error <- train$logcharges-train$pred
msetrain <- mean(train$error**2)
sqrt(msetrain)
#데이터셋 만들기
set.seed(2020)
synth.data<-data.frame(x1 =c(rnorm(20, 3, 1.5), rnorm(20,0,1), rnorm(20,5,1)),
x2 =c(rnorm(20, 0, 1), rnorm(20,4,1), rnorm(20,5,1)))
synth.data
View(synth.data)
synth.data<-data.frame(x1 =c(rnorm(20, 3, 1.5), rnorm(20,0,1), rnorm(20,5,1)),
x2 =c(rnorm(20, 0, 1), rnorm(20,4,1), rnorm(20,5,1)))
ndata<-nrow(synth.data)#행개수
ndim<-ncol(synth.data)#열개수
synth.data%>%ggplot(aes(x =x1, y=x2)) +geom_point(shape =1) +theme_bw()
library("dplyr")
synth.data%>%ggplot(aes(x =x1, y=x2)) +geom_point(shape =1) +theme_bw()
library("dplyr")
library("tidyr")
library('rpart') # Decision Tree
library('rpart') # Decision Tree
library('rpart.plot') # Decision Tree
library('ROCR') #AUC 그래프
library('ggplot2') #시각화
synth.data%>%ggplot(aes(x =x1, y=x2)) +geom_point(shape =1) +theme_bw()
#유클리디안거리 함수
u_dist<-function(u, v){sqrt(sum((u -v) **2))}
#초기 central 값
set.seed(2020)
k <-3
cents
cents <-data.frame(cl =1:k)
cents
View(cents)
cents <-cbind(cents, synth.data[sample(1:60, k),])
cents
sample(1:60, k)
cents <-cbind(cents, synth.data[sample(1:60, k),])
cents
#데이터셋 만들기
set.seed(2020)
synth.data<-data.frame(x1 =c(rnorm(20, 3, 1.5), rnorm(20,0,1), rnorm(20,5,1)),
x2 =c(rnorm(20, 0, 1), rnorm(20,4,1), rnorm(20,5,1)))
ndata<-nrow(synth.data)#행개수
ndim<-ncol(synth.data)#열개수
synth.data%>%ggplot(aes(x =x1, y=x2)) +geom_point(shape =1) +theme_bw()
#유클리디안거리 함수
u_dist<-function(u, v){sqrt(sum((u -v) **2))}
#초기 central 값
set.seed(2020)
k <-3
cents <-data.frame(cl =1:k)
cents <-cbind(cents, synth.data[sample(1:60, k),])
#군집분석 plot
synth.data$cl<-factor(rep(1, ndata), levels =1:k)
#군집분석 plot
synth.data$cl<-factor(rep(1, ndata), levels =1:k)
synth.data%>%ggplot(aes(x =x1, y=x2, col =cl)) +geom_point(shape =1) +theme_bw() +geom_point(data =cents, shape =4, col ='red')
cl
synth.data$cl
#군집분석 반복문
while(TRUE){
# data assignment to cluster
new_cl<-apply(synth.data[,1:ndim], 1, function(x) {
which.min(
apply(cents[,-1], 1, function(y) {
u_dist(y, x)
})
)
})
if(all(synth.data$cl==factor(new_cl))) break
synth.data$cl<-factor(new_cl)
cents <-synth.data%>%group_by(cl)%>%
summarise(x1 =mean(x1), x2 =mean(x2))
}
#데이터셋 만들기
set.seed(2020)
synth.data<-data.frame(x1 =c(rnorm(20, 3, 1.5), rnorm(20,0,1), rnorm(20,5,1)),
x2 =c(rnorm(20, 0, 1), rnorm(20,4,1), rnorm(20,5,1)))
ndim<-ncol(synth.data)#열개수
synth.data%>%ggplot(aes(x =x1, y=x2)) +geom_point(shape =1) +theme_bw()
#유클리디안거리 함수
u_dist<-function(u, v){sqrt(sum((u -v) **2))}
#초기 central 값
set.seed(2020)
cents <-data.frame(cl=1:k)
cents <-cbind(cents, synth.data[sample(1:60, k),])
#군집분석 plot
synth.data$cl<-factor(rep(1, ndata), levels =1:k)
synth.data%>%ggplot(aes(x =x1, y=x2, col =cl)) +geom_point(shape =1) +theme_bw() +geom_point(data =cents, shape =4, col ='red')
#군집분석 반복문
while(TRUE){
# data assignment to cluster
new_cl<-apply(synth.data[,1:ndim], 1, function(x) {
which.min(
apply(cents[,-1], 1, function(y) {
u_dist(y, x)
})
)
})
if(all(synth.data$cl==factor(new_cl))) break
synth.data$cl<-factor(new_cl)
cents <-synth.data%>%group_by(cl)%>%
summarise(x1 =mean(x1), x2 =mean(x2))
}
##군집분석 전처리
protein <-read.table("C:/Users/user/Documents/github_Rstudio_workspace/Data/protein.txt", sep="\t", header=TRUE)
vars.to.use<-colnames(protein)[-1] #나라 없애기
pmatrix<-scale(protein[,vars.to.use]) #  표준화
vars.to.use<-colnames(protein)[-1] #나라 없애기
#군집분석 전처리
protein <-read.table("C:/Users/user/Documents/github_Rstudio_workspace/Data/protein.txt", sep="\t", header=TRUE)
vars.to.use<-colnames(protein)[-1] #나라 없애기
protein[,vars.to.use]
pmatrix<-scale(protein[,vars.to.use]) #  표준화
pmatrix
pcenter<-attr(pmatrix, "scaled:center") # 평균 저장
pcenter
pscale<-attr(pmatrix, "scaled:scale") #표준편차 저장
#군집분석
pclusters<-kmeans(pmatrix, 5, nstart=100, iter.max=100) # 2번쨰=k값, 100번반복하겠다
pclusters$centers# 각각 군집의 편균값 어떤 특징인지 볼 수 있음
pclusters$size# 각 군집당 몇개인가
print_clusters(pclusters$cluster,5)
print_clusters(pclusters$cluster,5)
print_clusters(pclusters$cluster,5)
summary(pclusters)
pclusters$centers# 각각 군집의 편균값 어떤 특징인지 볼 수 있음
pclusters$size# 각 군집당 몇개인가
summary(pclusters)
print_clusters(pclusters$cluster,5)
#지표 추출
pclusters$withinss
(wss<-sum(pclusters$withinss))
(tss<-pclusters$totss)
(bss<-pclusters$betweenss)
ch.index<-(bss/(k-1)) /(wss/(ndata-k))
print(sprintf('CH index of this clustering is %.f', ch.index))
#bmi_wide
#exercise02
bmic <- read.csv('C:/Users/user/Documents/github_Rstudio_workspace/Data/bmi_cc.csv', header=TRUE)
head(bmic)
bmic_clean <- separate(bmic,Country_ISO,c('Country','ISO'),sep='/')
bmic_clean
#bmi_wide
#exercise02
bmic <- read.csv('C:/Users/user/Documents/github_Rstudio_workspace/Data/bmi_cc.csv', header=TRUE)
head(bmic)
bmic_clean <- separate(bmic,Country_ISO,c('Country','ISO'),sep='/')
unite(bmic_clean,Country_ISO,Country,ISO, sep='/')
bmic_clean <- separate(bmic,Country_ISO,c('Country','ISO'),sep='/')
bmic_clean
